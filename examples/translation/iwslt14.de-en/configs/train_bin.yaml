task:
  class: TranslationTask
  mode: train
  src: de
  tgt: en
  maxlen: 256
  index_only: True
  tokenizer:
    class: FastBPE
    vocab: resources/vocabulary/vocab
    add_bos: True
    add_eos: True
  dataloader:
    train:
      class: BinarizedDataLoader
      path: train.bin
      preload: True
    valid:
      class: InMemoryDataLoader
      sampler:
        class: SequentialSampler
        max_samples: 128
    test:
      class: InMemoryDataLoader
      sampler:
        class: SequentialSampler
        max_samples: 128
  data:
    valid:
      class: ParallelTextDataset
      sort_samples: True
      path:
        de: data/valid.de
        en: data/valid.en
    test:
      class: ParallelTextDataset
      sort_samples: True
      path:
        de: data/test.de
        en: data/test.en
  model:
    class: Seq2Seq
    encoder:
      class: TransformerEncoder
      num_layers: 6
      d_model: 512
      n_head: 4
      dim_feedforward: 1024
      dropout: 0.3
      activation: 'relu'
    decoder:
      class: TransformerDecoder
      num_layers: 6
      d_model: 512
      n_head: 4
      dim_feedforward: 1024
      dropout: 0.3
      activation: 'relu'
    share_embedding: decoder-input-output
    d_model: 512
  criterion:
    class: LabelSmoothedCrossEntropy
    epsilon: 0.1
  trainer:
    class: Trainer
    optimizer:
      class: AdamW
      lr:
        class: InverseSquareRootRateScheduler
        warmup_steps: 4000
        rate: 5e-4
      clip_norm: 0.
      weight_decay: 1e-4
      betas: (0.9, 0.98)
    max_steps: 50000
    validate_interval_step: 4000
    assess_by: valid.bleu
    save_model_dir: checkpoints
  generator:
    class: SequenceGenerator
    search:
      class: BeamSearch
      maxlen_coef: (1.2, 10)
      beam: 5
      lenpen: 0.6
  evaluator:
    class: Evaluator
    metric:
      bleu:
        class: BLEU
env:
  device: cuda
  fp16: True
